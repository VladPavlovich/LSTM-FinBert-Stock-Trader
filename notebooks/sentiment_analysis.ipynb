{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#will be using FINBERT model for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\r\n",
      "  Obtaining dependency information for transformers from https://files.pythonhosted.org/packages/8d/10/8cef2288810a3210659eb3a20711e8387cc35a881a7762ae387806e2d651/transformers-4.53.1-py3-none-any.whl.metadata\r\n",
      "  Downloading transformers-4.53.1-py3-none-any.whl.metadata (40 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m40.9/40.9 kB\u001B[0m \u001B[31m1.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: filelock in /Users/vladpavlovich/PycharmProjects/LSM-FinBert-Trader/venv/lib/python3.9/site-packages (from transformers) (3.18.0)\r\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\r\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.30.0 from https://files.pythonhosted.org/packages/44/f4/5f3f22e762ad1965f01122b42dae5bf0e009286e2dba601ce1d0dba72424/huggingface_hub-0.33.2-py3-none-any.whl.metadata\r\n",
      "  Downloading huggingface_hub-0.33.2-py3-none-any.whl.metadata (14 kB)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/vladpavlovich/PycharmProjects/LSM-FinBert-Trader/venv/lib/python3.9/site-packages (from transformers) (2.0.2)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/vladpavlovich/PycharmProjects/LSM-FinBert-Trader/venv/lib/python3.9/site-packages (from transformers) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/vladpavlovich/PycharmProjects/LSM-FinBert-Trader/venv/lib/python3.9/site-packages (from transformers) (6.0.2)\r\n",
      "Collecting regex!=2019.12.17 (from transformers)\r\n",
      "  Obtaining dependency information for regex!=2019.12.17 from https://files.pythonhosted.org/packages/7a/d1/598de10b17fdafc452d11f7dada11c3be4e379a8671393e4e3da3c4070df/regex-2024.11.6-cp39-cp39-macosx_11_0_arm64.whl.metadata\r\n",
      "  Downloading regex-2024.11.6-cp39-cp39-macosx_11_0_arm64.whl.metadata (40 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m40.5/40.5 kB\u001B[0m \u001B[31m5.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: requests in /Users/vladpavlovich/PycharmProjects/LSM-FinBert-Trader/venv/lib/python3.9/site-packages (from transformers) (2.32.4)\r\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\r\n",
      "  Obtaining dependency information for tokenizers<0.22,>=0.21 from https://files.pythonhosted.org/packages/6c/e6/33f41f2cc7861faeba8988e7a77601407bf1d9d28fc79c5903f8f77df587/tokenizers-0.21.2-cp39-abi3-macosx_11_0_arm64.whl.metadata\r\n",
      "  Downloading tokenizers-0.21.2-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\r\n",
      "Collecting safetensors>=0.4.3 (from transformers)\r\n",
      "  Obtaining dependency information for safetensors>=0.4.3 from https://files.pythonhosted.org/packages/b8/3b/11f1b4a2f5d2ab7da34ecc062b0bc301f2be024d110a6466726bec8c055c/safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata\r\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\r\n",
      "Collecting tqdm>=4.27 (from transformers)\r\n",
      "  Obtaining dependency information for tqdm>=4.27 from https://files.pythonhosted.org/packages/d0/30/dc54f88dd4a2b5dc8a0279bdd7270e735851848b762aeb1c1184ed1f6b14/tqdm-4.67.1-py3-none-any.whl.metadata\r\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m57.7/57.7 kB\u001B[0m \u001B[31m5.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: fsspec>=2023.5.0 in /Users/vladpavlovich/PycharmProjects/LSM-FinBert-Trader/venv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/vladpavlovich/PycharmProjects/LSM-FinBert-Trader/venv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\r\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub<1.0,>=0.30.0->transformers)\r\n",
      "  Obtaining dependency information for hf-xet<2.0.0,>=1.1.2 from https://files.pythonhosted.org/packages/de/5f/2c78e28f309396e71ec8e4e9304a6483dcbc36172b5cea8f291994163425/hf_xet-1.1.5-cp37-abi3-macosx_11_0_arm64.whl.metadata\r\n",
      "  Downloading hf_xet-1.1.5-cp37-abi3-macosx_11_0_arm64.whl.metadata (879 bytes)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/vladpavlovich/PycharmProjects/LSM-FinBert-Trader/venv/lib/python3.9/site-packages (from requests->transformers) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/vladpavlovich/PycharmProjects/LSM-FinBert-Trader/venv/lib/python3.9/site-packages (from requests->transformers) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/vladpavlovich/PycharmProjects/LSM-FinBert-Trader/venv/lib/python3.9/site-packages (from requests->transformers) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/vladpavlovich/PycharmProjects/LSM-FinBert-Trader/venv/lib/python3.9/site-packages (from requests->transformers) (2025.6.15)\r\n",
      "Downloading transformers-4.53.1-py3-none-any.whl (10.8 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m10.8/10.8 MB\u001B[0m \u001B[31m26.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading huggingface_hub-0.33.2-py3-none-any.whl (515 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m515.4/515.4 kB\u001B[0m \u001B[31m21.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading regex-2024.11.6-cp39-cp39-macosx_11_0_arm64.whl (284 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m284.6/284.6 kB\u001B[0m \u001B[31m13.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m418.4/418.4 kB\u001B[0m \u001B[31m22.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading tokenizers-0.21.2-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.7/2.7 MB\u001B[0m \u001B[31m14.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m78.5/78.5 kB\u001B[0m \u001B[31m8.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading hf_xet-1.1.5-cp37-abi3-macosx_11_0_arm64.whl (2.6 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.6/2.6 MB\u001B[0m \u001B[31m23.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: tqdm, safetensors, regex, hf-xet, huggingface-hub, tokenizers, transformers\r\n",
      "Successfully installed hf-xet-1.1.5 huggingface-hub-0.33.2 regex-2024.11.6 safetensors-0.5.3 tokenizers-0.21.2 tqdm-4.67.1 transformers-4.53.1\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.1.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-05T05:59:44.855422Z",
     "start_time": "2025-07-05T05:59:36.925559Z"
    }
   },
   "id": "85fa1a70c24092ca"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vladpavlovich/PycharmProjects/LSM-FinBert-Trader/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/533 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "88d763fbf66240e89ff0c19aa4f97e6b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "vocab.txt: 0.00B [00:00, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f9c2ab7c4b14473a82a008da62d81127"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "pytorch_model.bin:   0%|          | 0.00/439M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2679eeec8c5c4742b61a25a5e573a826"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30873, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=3, bias=True)\n)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
    "model.eval()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-05T06:01:02.931739Z",
     "start_time": "2025-07-05T06:00:41.335191Z"
    }
   },
   "id": "30572887f23c3e"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_sentiment_score(texts):\n",
    "    scores = []\n",
    "    for text in texts:\n",
    "        inputs = tokenizer(text, return_tensors='pt', truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            probs = F.softmax(outputs.logits, dim=1)\n",
    "            score = probs[0][2] - probs[0][0]  # positive - negative\n",
    "            scores.append(score.item())\n",
    "    return sum(scores) / len(scores) if scores else 0.0\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-05T06:01:28.385202Z",
     "start_time": "2025-07-05T06:01:28.381341Z"
    }
   },
   "id": "a2f4e5edb1d8d1ee"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def fetch_apple_news(date, api_key):\n",
    "    \"\"\"\n",
    "    Fetches news headlines for Apple on a given date.\n",
    "    Returns a list of headline strings.\n",
    "    \"\"\"\n",
    "    url = \"https://newsapi.org/v2/everything\"\n",
    "    params = {\n",
    "        \"q\": \"Apple OR AAPL\",\n",
    "        \"from\": date,\n",
    "        \"to\": date,\n",
    "        \"language\": \"en\",\n",
    "        \"sortBy\": \"relevancy\",\n",
    "        \"pageSize\": 30,\n",
    "        \"apiKey\": \"c69d24631c9249a6ad530e984ba3889e\"\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "    \n",
    "    if \"articles\" in data:\n",
    "        return [article[\"title\"] for article in data[\"articles\"]]\n",
    "    else:\n",
    "        print(\"Error:\", data.get(\"message\", \"Unknown error\"))\n",
    "        return []\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-05T06:12:58.737137Z",
     "start_time": "2025-07-05T06:12:58.711316Z"
    }
   },
   "id": "5d1faa35f6ae2491"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headlines: ['Pilou Asbæk on Playing the Mule, ‘Foundation’ Season 3’s Terrifying Villain', 'The Ploopy Knob is an open-source control dial for your PC', \"The MacRumors Show: Apple's Plan to Launch Low-Cost MacBook With iPhone Chip\", 'iPhone 17 Pro Coming Soon With These 14 New Features', 'When will F1 movie be on Apple TV? Here’s the streaming release date', '4th of July Apple sale: Save up to $800 on hardware, monitors & more', \"Siri's future, the original iPhone's past, and Apple Music's birthday on the AppleInsider Podcast\", 'All of the best 4th of July Apple deals', 'Apple just released a weirdly interesting coding language model', \"Here's why the Oura Ring 4 is a postpartum mum's unexpected best friend\", 'The iPhone 17 Pro will wirelessly charge your Apple Watch and AirPods, according to news leaks', 'A rare look inside the durability lab where Apple tortures its products', 'These were the most-watched Apple TV+ movies and shows in June', \"Tim Cook isn't going to get fired, and Steve Jobs isn't rolling over in his grave\", 'This is the letter Donald Trump sent Apple to keep TikTok on the App Store', \"iOS 26: What's Changed With the iPhone's Home Screen\", 'Weddings are a must-attend on the billionaire social calendar for the summer', 'Apple is prepping 15 new Macs for release, including one potential surprise', 'Best Apple Deals of the Week: Big Discounts Arrive for AirPods Max, Apple Pencil Pro, AirTag, and More', 'Five best iOS 26 features that will help you be more creative', 'DOJ lack of TikTok ban enforcement appears to be due to broad Article II interpretation', 'Things We Loved in Music This Week: July 4', \"Counterpoint: Huawei and Apple lead China's Q2 smartphone shipments\", 'iPhone Sales Finally Bounce Back in China', 'M5 Chip Rumored to Debut in These Five Apple Products Later This Year', '6 New Albums You Should Listen to Now: Kesha, Nilüfer Yanya, and More', \"Here's When to Expect Apple's Answer to Meta's Ray-Ban Smart Glasses\", 'Ten best Mac games to buy during the Steam Summer Sale', 'Joey Chestnut eating records: King of more than hot dogs', 'Apple Loop: iPhone Fold Launch Dates, The Apple Logo Mystery, Surprise iPhone 17 Upgrade']\n",
      "2025-07-04 sentiment score: -0.7403426068868952\n"
     ]
    }
   ],
   "source": [
    "api_key = \"c69d24631c9249a6ad530e984ba3889e\"  # \n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Today's date\n",
    "date = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "headlines = fetch_apple_news(date, api_key)\n",
    "print(\"Headlines:\", headlines)\n",
    "\n",
    "sentiment = get_sentiment_score(headlines)\n",
    "print(f\"{date} sentiment score:\", sentiment)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-05T06:13:03.707374Z",
     "start_time": "2025-07-05T06:13:01.820408Z"
    }
   },
   "id": "b75a9c5a893de75f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
