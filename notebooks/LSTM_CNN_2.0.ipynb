{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-06T03:21:57.047397Z",
     "start_time": "2025-07-06T03:21:57.040172Z"
    }
   },
   "outputs": [],
   "source": [
    "import random, numpy as np, pandas as pd, torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import yfinance as yf, ta\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED);  np.random.seed(SEED)\n",
    "torch.manual_seed(SEED);  torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic, torch.backends.cudnn.benchmark = True, False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l6/kt268nls2sqcx51m4w_z09pc0000gn/T/ipykernel_71433/1144416275.py:4: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(\"AAPL\", start=start_date, end=end_date)\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final DataFrame shape: (1635, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/var/folders/l6/kt268nls2sqcx51m4w_z09pc0000gn/T/ipykernel_71433/1144416275.py:21: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)\n",
      "/var/folders/l6/kt268nls2sqcx51m4w_z09pc0000gn/T/ipykernel_71433/1144416275.py:22: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "start_date = \"2019-01-01\"\n",
    "end_date   = datetime.today().strftime('%Y-%m-%d')\n",
    "#end_date = \"2025-05-05\"\n",
    "df = yf.download(\"AAPL\", start=start_date, end=end_date)\n",
    "\n",
    "# flatten MultiIndex cols if present\n",
    "df.columns = [c[0] if isinstance(c, tuple) else c for c in df.columns]\n",
    "df = df[['Open', 'High', 'Low', 'Close', 'Volume']].copy().dropna()\n",
    "\n",
    "# engineered + TA features\n",
    "df['Return']       = df['Close'].pct_change()\n",
    "df['Candle_Body']  = df['Close'] - df['Open']\n",
    "df['Range']        = df['High']  - df['Low']\n",
    "df['rsi']          = ta.momentum.RSIIndicator(df['Close']).rsi()\n",
    "df['macd']         = ta.trend.MACD(df['Close']).macd_diff()\n",
    "df['ema_10']       = ta.trend.EMAIndicator(df['Close'], 10).ema_indicator()\n",
    "df['bb_bbw']       = ta.volatility.BollingerBands(df['Close']).bollinger_wband()\n",
    "df['adx']          = ta.trend.ADXIndicator(df['High'], df['Low'], df['Close']).adx()\n",
    "df['stoch']        = ta.momentum.StochasticOscillator(df['High'], df['Low'], df['Close']).stoch()\n",
    "\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "df.fillna(method='bfill', inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "print(\"Final DataFrame shape:\", df.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-06T03:21:57.197499Z",
     "start_time": "2025-07-06T03:21:57.062408Z"
    }
   },
   "id": "c474ad7969602daf"
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 1333 samples, window (30, 14) (seq, features)\n"
     ]
    }
   ],
   "source": [
    "feature_cols = df.columns.tolist()\n",
    "feature_cols.remove('Close')        # keep Close only for label\n",
    "scaler       = MinMaxScaler()\n",
    "scaled_feats = scaler.fit_transform(df[feature_cols])\n",
    "scaled_close = MinMaxScaler().fit_transform(df[['Close']])\n",
    "scaled_all   = np.concatenate([scaled_close, scaled_feats], axis=1)  # shape (*,14)\n",
    "\n",
    "SEQ_LEN  = 30\n",
    "X, y     = [], []\n",
    "thresh   = 0.003\n",
    "\n",
    "for i in range(SEQ_LEN, len(scaled_all) - 3):\n",
    "    window = scaled_all[i-SEQ_LEN:i]\n",
    "    change = scaled_all[i+3][0] - scaled_all[i][0]  # 3-day look-ahead on Close\n",
    "    if   change >  thresh:  y.append(1)\n",
    "    elif change < -thresh:  y.append(0)\n",
    "    else:                   continue\n",
    "    X.append(window)\n",
    "\n",
    "X, y = np.array(X), np.array(y)\n",
    "print(f\"Dataset: {X.shape[0]} samples, window {X.shape[1:]} (seq, features)\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-06T03:21:57.201003Z",
     "start_time": "2025-07-06T03:21:57.192831Z"
    }
   },
   "id": "55611e2e380c887a"
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loader check: torch.Size([64, 30, 14])\n"
     ]
    }
   ],
   "source": [
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "ds       = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "train_len = int(0.8 * len(ds))\n",
    "val_len   = int(0.1 * len(ds))\n",
    "test_len  = len(ds) - train_len - val_len\n",
    "train_ds, val_ds, test_ds = random_split(ds, [train_len, val_len, test_len],\n",
    "                                         generator=torch.Generator().manual_seed(SEED))\n",
    "\n",
    "BATCH = 64\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH)\n",
    "\n",
    "print(\"Loader check:\", next(iter(train_loader))[0].shape)  # (B,30,14)\n",
    "\n",
    "# Save test data for external evaluation (e.g., FinBERT integration)\n",
    "X_test_np = X_tensor[test_ds.indices].numpy()\n",
    "y_test_np = y_tensor[test_ds.indices].numpy()\n",
    "#np.save(\"X_test_pre_may.npy\", X_test_np)\n",
    "#np.save(\"y_test_pre_may.npy\", y_test_np)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-06T03:21:57.256186Z",
     "start_time": "2025-07-06T03:21:57.201513Z"
    }
   },
   "id": "bb57dd022727c1d3"
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "class LSTM_CNN_Attention(nn.Module):\n",
    "    def __init__(self, input_size, lstm_hidden=64, cnn_out=24, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, lstm_hidden, batch_first=True, bidirectional=True)\n",
    "        self.ln   = nn.LayerNorm(2 * lstm_hidden)\n",
    "\n",
    "        self.conv1 = nn.Conv1d(2*lstm_hidden, cnn_out, 3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm1d(cnn_out)\n",
    "        self.conv2 = nn.Conv1d(cnn_out, cnn_out, 3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm1d(cnn_out)\n",
    "        self.cnn_drop = nn.Dropout(0.2)\n",
    "\n",
    "        self.attn_fc  = nn.Linear(cnn_out, 32)\n",
    "        self.attn_vec = nn.Linear(32, 1)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.head    = nn.Sequential(\n",
    "            nn.Linear(cnn_out, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h, _  = self.lstm(x)\n",
    "        h     = self.ln(h)\n",
    "        c     = h.permute(0,2,1)\n",
    "        c     = F.relu(self.bn1(self.conv1(c)))\n",
    "        c     = F.relu(self.bn2(self.conv2(c)))\n",
    "        c     = self.cnn_drop(c).permute(0,2,1)\n",
    "\n",
    "        e  = torch.tanh(self.attn_fc(c))\n",
    "        w  = F.softmax(self.attn_vec(e), dim=1)\n",
    "        ctx = torch.sum(w * c, dim=1)\n",
    "        out = self.dropout(ctx)\n",
    "        return self.head(out)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-06T03:21:57.262255Z",
     "start_time": "2025-07-06T03:21:57.260690Z"
    }
   },
   "id": "4e8d2fb14b037185"
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01  TrainAcc 0.4972  ValAcc 0.5038  LR 0.00100\n",
      "Epoch 02  TrainAcc 0.5779  ValAcc 0.5714  LR 0.00100\n",
      "Epoch 03  TrainAcc 0.5732  ValAcc 0.4135  LR 0.00100\n",
      "Epoch 04  TrainAcc 0.5797  ValAcc 0.4511  LR 0.00100\n",
      "Epoch 05  TrainAcc 0.5732  ValAcc 0.5564  LR 0.00050\n",
      "Epoch 06  TrainAcc 0.5929  ValAcc 0.5714  LR 0.00050\n",
      "Epoch 07  TrainAcc 0.5863  ValAcc 0.5789  LR 0.00050\n",
      "Epoch 08  TrainAcc 0.5882  ValAcc 0.5940  LR 0.00050\n",
      "Epoch 09  TrainAcc 0.5947  ValAcc 0.5489  LR 0.00050\n",
      "Epoch 10  TrainAcc 0.6126  ValAcc 0.5639  LR 0.00050\n",
      "Epoch 11  TrainAcc 0.6013  ValAcc 0.5789  LR 0.00025\n",
      "Epoch 12  TrainAcc 0.6107  ValAcc 0.5865  LR 0.00025\n",
      "Epoch 13  TrainAcc 0.5994  ValAcc 0.6015  LR 0.00025\n",
      "Epoch 14  TrainAcc 0.6126  ValAcc 0.5940  LR 0.00025\n",
      "Epoch 15  TrainAcc 0.6004  ValAcc 0.6015  LR 0.00025\n",
      "Epoch 16  TrainAcc 0.6088  ValAcc 0.5789  LR 0.00013\n",
      "Epoch 17  TrainAcc 0.6107  ValAcc 0.5714  LR 0.00013\n",
      "Epoch 18  TrainAcc 0.6173  ValAcc 0.5639  LR 0.00013\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "model      = LSTM_CNN_Attention(input_size=X_tensor.shape[2]).to(device)\n",
    "optimizer  = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "criterion  = nn.CrossEntropyLoss()\n",
    "\n",
    "# ↓ scheduler cuts LR by ½ if val-acc hasn’t improved for 2 epochs\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer, mode=\"max\", factor=0.5, patience=2)   # ← no verbose\n",
    "\n",
    "\n",
    "best_state, best_val, patience, wait = None, 0, 5, 0\n",
    "EPOCHS = 50\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    # ----- train -----\n",
    "    model.train()\n",
    "    tr_loss = tr_corr = tr_cnt = 0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss   = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        tr_loss += loss.item() * yb.size(0)\n",
    "        tr_corr += (logits.argmax(1) == yb).sum().item()\n",
    "        tr_cnt  += yb.size(0)\n",
    "    tr_acc = tr_corr / tr_cnt\n",
    "\n",
    "    # ----- validate -----\n",
    "    model.eval()\n",
    "    v_corr = v_cnt = 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            preds  = model(xb).argmax(1)\n",
    "            v_corr += (preds == yb).sum().item()\n",
    "            v_cnt  += yb.size(0)\n",
    "    v_acc = v_corr / v_cnt\n",
    "\n",
    "    # Step scheduler on validation accuracy\n",
    "    scheduler.step(v_acc)\n",
    "\n",
    "    current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "    print(f\"Epoch {epoch:02}  TrainAcc {tr_acc:.4f}  ValAcc {v_acc:.4f}  LR {current_lr:.5f}\")\n",
    "\n",
    "    # ----- early stop -----\n",
    "    if v_acc > best_val:\n",
    "        best_val, best_state, wait = v_acc, {k: v.cpu() for k, v in model.state_dict().items()}, 0\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "# Restore best-validation weights\n",
    "model.load_state_dict(best_state)\n",
    "model.to(device)\n",
    "# Save the best model\n",
    "torch.save(model.state_dict(), \"pre-may-model.pth\")\n",
    "# Save test data\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-06T03:22:06.666486Z",
     "start_time": "2025-07-06T03:21:57.268324Z"
    }
   },
   "id": "42f31cdba1a7783a"
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6493\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "t_corr = t_cnt = 0\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        t_corr += (model(xb).argmax(1)==yb).sum().item(); t_cnt += yb.size(0)\n",
    "print(\"Test Accuracy:\", round(t_corr/t_cnt, 4))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-06T03:22:06.702017Z",
     "start_time": "2025-07-06T03:22:06.667416Z"
    }
   },
   "id": "d0012a83e4ab684b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
